{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Assignment 1 - All About torch.Tensor\n\n### Deep Learning with PyTorch: Zero to Gans\n\nAn short introduction about PyTorch and about the chosen functions. \n- Fill Diagonal\n- Eigenvalues\n- Reshape\n- Least Squares\n- Unique"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Import torch and other required modules\nimport torch","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fill Diagonal - fill_diagonal_()\n\nAccording to the PyTorch Documentation, this function fills the main diagonal of a tensor (must be a matrix). Dimensions must be > 2"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 1 - working\ntest = torch.tensor([[1, 2, 3], \n                    [5, 43, 2],\n                    [67, 5, 32]])\n\ntest.fill_diagonal_(10)","execution_count":17,"outputs":[{"data":{"text/plain":"tensor([[10,  2,  3],\n        [ 5, 10,  2],\n        [67,  5, 10]])"},"execution_count":17,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"Even in a nonzero matrix, the fill_diagonal_ function still diagnolizes the matrix to the specified parameter"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 2 - working\nw = torch.zeros(6,6)\ny = torch.zeros(7,7)\nz = torch.zeros(8,8)\nlst = [w, y, z]\na = 6\n\nfor i in lst:\n    i.fill_diagonal_(a)\n    a += 1\n    print(i)","execution_count":15,"outputs":[{"name":"stdout","output_type":"stream","text":"tensor([[6., 0., 0., 0., 0., 0.],\n        [0., 6., 0., 0., 0., 0.],\n        [0., 0., 6., 0., 0., 0.],\n        [0., 0., 0., 6., 0., 0.],\n        [0., 0., 0., 0., 6., 0.],\n        [0., 0., 0., 0., 0., 6.]])\ntensor([[7., 0., 0., 0., 0., 0., 0.],\n        [0., 7., 0., 0., 0., 0., 0.],\n        [0., 0., 7., 0., 0., 0., 0.],\n        [0., 0., 0., 7., 0., 0., 0.],\n        [0., 0., 0., 0., 7., 0., 0.],\n        [0., 0., 0., 0., 0., 7., 0.],\n        [0., 0., 0., 0., 0., 0., 7.]])\ntensor([[8., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 8., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 8., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 8., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 8., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 8., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 8., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 8.]])\n"}]},{"metadata":{},"cell_type":"markdown","source":"Diagnolizing zero matrices to create a stair like pattern"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 3 - breaking (to illustrate when it breaks)\ntest = torch.tensor(10)\n\ntest.fill_diagonal_(10.)\n\nprint(test)","execution_count":24,"outputs":[{"ename":"RuntimeError","evalue":"dimensions must larger than 1","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-a5a1c8ef0426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_diagonal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: dimensions must larger than 1"]}]},{"metadata":{},"cell_type":"markdown","source":"As said before, the function requires that the dimensions of the matrix be more than 2. A single number tensor breaks the function."},{"metadata":{},"cell_type":"markdown","source":"This is a very useful function when you need to create certain matrices for machine learning."},{"metadata":{},"cell_type":"markdown","source":"## Eigenvalues - torch.eig()\n\nAn eigenvalue is the factor by which an eigenvector is stretched by a transformation within a system of equations.\n\ntorch.eig() finds the eigenvalues and eigenvectors of a real square matrix."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 1 - working\n\nx = torch.tensor([[8,3,10],\n                 [9,4,1],\n                 [5,2,50]], dtype=torch.float64)\n\ntorch.eig(x)","execution_count":6,"outputs":[{"data":{"text/plain":"torch.return_types.eig(\neigenvalues=tensor([[ 0.4352,  0.0000],\n        [10.2556,  0.0000],\n        [51.3092,  0.0000]], dtype=torch.float64),\neigenvectors=tensor([], dtype=torch.float64))"},"execution_count":6,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"As seen, torch.eig() found the eigen values of the square 3x3 matrix: .4352, 10.2556, 51.3092"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 2 - working\n\ny = torch.randn(3,3)\n\ntorch.eig(y, eigenvectors=True)","execution_count":3,"outputs":[{"data":{"text/plain":"torch.return_types.eig(\neigenvalues=tensor([[-0.0081,  0.9385],\n        [-0.0081, -0.9385],\n        [ 1.3846,  0.0000]]),\neigenvectors=tensor([[ 0.0777, -0.4747, -0.3504],\n        [-0.8447,  0.0000,  0.5240],\n        [-0.1027, -0.2110,  0.7763]]))"},"execution_count":3,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"torch.eig() finds the eigenvectors by utilizing the eigenvectors parameter with a boolean value. If True, the eigenvectors are found as well, which can be seen in the above output."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 3 - breaking (to illustrate when it breaks)\n\nz = torch.tensor([[4],\n                 [5],\n                 [6]], dtype=torch.float64)\n\ntorch.eig(z)","execution_count":11,"outputs":[{"ename":"RuntimeError","evalue":"invalid argument 1: A should be square at /opt/conda/conda-bld/pytorch_1587428266983/work/aten/src/TH/generic/THTensorLapack.cpp:194","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-abec7cee9424>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  [6]], dtype=torch.float64)\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: invalid argument 1: A should be square at /opt/conda/conda-bld/pytorch_1587428266983/work/aten/src/TH/generic/THTensorLapack.cpp:194"]}]},{"metadata":{},"cell_type":"markdown","source":"This vector breaks the function because eigenvalues can only be found in square matrices."},{"metadata":{},"cell_type":"markdown","source":"I've yet to learn the applications of eigenvalues for deep learning, but this must be an important concept in building these type of models."},{"metadata":{},"cell_type":"markdown","source":"## Reshape - torch.reshape()\n\nReshapes the dimensios of a tensor, so an n x m matrix can be converted into a m x n matrix."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 1 - working\n\nx = torch.randn(2,2)\n\nprint(torch.reshape(x, (1,4)))\ntorch.reshape(x, (4,1))","execution_count":13,"outputs":[{"name":"stdout","output_type":"stream","text":"tensor([[0.1186, 1.6138, 2.7505, 0.1806]])\n"},{"data":{"text/plain":"tensor([[0.1186],\n        [1.6138],\n        [2.7505],\n        [0.1806]])"},"execution_count":13,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"Reshapes the square matrix into a one-row matrix and into a vector."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 2 - working\n\ny = torch.randn(16,1)\n\ntorch.reshape(y, (4,4))","execution_count":16,"outputs":[{"data":{"text/plain":"tensor([[ 0.1659,  0.1526,  0.4596, -0.2001],\n        [ 0.0945, -0.0795, -0.0407, -0.8284],\n        [ 0.3444, -0.9219,  0.9632, -0.1889],\n        [-0.8507,  0.5135,  0.1139,  0.1020]])"},"execution_count":16,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"Reshapes an entire vector into a neat 4x4 matrix. This emphasizes the need for the requested reshape to match the number of entities within the matrix."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 3 - breaking (to illustrate when it breaks)\n\nz = torch.randn(4,4)\n\ntorch.reshape(z, (5,5))","execution_count":17,"outputs":[{"ename":"RuntimeError","evalue":"shape '[5, 5]' is invalid for input of size 16","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-bf9b8cc184a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: shape '[5, 5]' is invalid for input of size 16"]}]},{"metadata":{},"cell_type":"markdown","source":"Example of what happens when the number of entities doesn't match the requested reshape."},{"metadata":{},"cell_type":"markdown","source":"Definitely a useful function for transforming a tensor to a shape to best fit certain matrix operations in machine learning."},{"metadata":{},"cell_type":"markdown","source":"## Least Squares\n\nFinds solution to the least squares and least norm problems for a m x n matrix and a m x k matrix."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 1 - working\n\nx = torch.randn(5,5)\ny = torch.randn(5,2)\n\ntorch.lstsq(y, x)","execution_count":18,"outputs":[{"data":{"text/plain":"torch.return_types.lstsq(\nsolution=tensor([[ 1.7575, -0.2247],\n        [ 1.7702, -0.6291],\n        [-0.1232,  0.6687],\n        [ 0.1176, -0.9535],\n        [ 0.4702,  0.6696]]),\nQR=tensor([[ 1.7401, -0.6656,  0.8801, -1.0346, -1.3289],\n        [ 0.0209,  1.3381,  1.0780,  1.0486, -0.7973],\n        [ 0.5526, -0.2711, -2.1116,  0.7179,  0.2614],\n        [ 0.4871, -0.2520,  0.7736,  1.2741,  0.0740],\n        [-0.2030,  0.2264, -0.5137, -0.0124,  0.6452]]))"},"execution_count":18,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"If m >= n in x, then lstsq() returns the least squares solution "},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 2 - working\n\nx = torch.randn(4,6)\ny = torch.randn(4,3)\n\ntorch.lstsq(y,x)","execution_count":20,"outputs":[{"data":{"text/plain":"torch.return_types.lstsq(\nsolution=tensor([[ 0.2770, -0.2452, -0.1787],\n        [ 0.5487, -0.4738, -0.3252],\n        [-0.6256,  0.1975, -0.0835],\n        [ 0.2857, -0.4067, -0.5847],\n        [-0.3278,  0.3651,  0.3471],\n        [-0.3249, -0.1104, -0.4045]]),\nQR=tensor([[-2.7082,  0.0495,  0.0041, -0.8697, -0.1465,  0.0413],\n        [ 0.7410,  2.6154, -0.1434, -0.0650,  0.2551, -0.5636],\n        [-0.7550, -1.0817,  1.5342, -0.3791,  0.4748, -0.2725],\n        [-0.7039, -0.6512, -0.3462, -2.0219, -0.3021,  0.5164]]))"},"execution_count":20,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"If m < n in x, then lstsq() returns least norm solution"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 3 - breaking (to illustrate when it breaks\n\nx = torch.randn(3,3)\ny = torch.randn(4,3)\n\ntorch.lstsq(y,x)","execution_count":21,"outputs":[{"ename":"RuntimeError","evalue":"Expected A and b to have same size at dim 0, but A has 3 rows and B has 4 rows","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-422c64355c06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: Expected A and b to have same size at dim 0, but A has 3 rows and B has 4 rows"]}]},{"metadata":{},"cell_type":"markdown","source":"The lstsq() function breaks when the number of rows in the matrices do not match. This is because if the rows are the number of observations and the columns the number of features, than both matrices must have the same number of observations, otherwise the datasets must not be the same."},{"metadata":{},"cell_type":"markdown","source":"This is a useful function for understanding better the best fitting line of a regression model."},{"metadata":{},"cell_type":"markdown","source":"## Unique - torch.unique()\n\nReturns the unique values in a tensor, which is presumably a vector or matrix"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 1 - working\n\nx = torch.randn(3,3)\n\nprint(x)\ntorch.unique(x)","execution_count":14,"outputs":[{"name":"stdout","output_type":"stream","text":"tensor([[ 0.4792,  0.4610,  0.3354],\n        [-1.0780,  0.5112, -1.0263],\n        [-0.2547, -0.4566, -1.0496]])\n"},{"data":{"text/plain":"tensor([-1.0780, -1.0496, -1.0263, -0.4566, -0.2547,  0.3354,  0.4610,  0.4792,\n         0.5112])"},"execution_count":14,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"A simple example of the funtion in action, returning the unique values of x."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 2 - working\n\nw = torch.tensor([[2,2,3],\n             [2,4,2],\n             [1,2,2]])\n\ny = torch.tensor([[3,3,2],\n                  [3,1,3],\n                  [4,3,3]])\n\nprint(torch.unique(w))\nprint(torch.unique(y))\n\nsolution = 1**2 + 2**2 + 3**2 + 4**2\n\nproduct = torch.unique(w) * torch.unique(y)\n\nprint(product)\nprint('Solution: ', solution)\n\ntorch.sum(product) == solution","execution_count":4,"outputs":[{"name":"stdout","output_type":"stream","text":"tensor([1, 2, 3, 4])\ntensor([1, 2, 3, 4])\ntensor([ 1,  4,  9, 16])\nSolution:  30\n"},{"data":{"text/plain":"tensor(True)"},"execution_count":4,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"Here I created tensors that have their 2 and 3 as modes and a unique value in each row. I wanted to play around with mathematical and conditional operators with PyTorch so I wrote the above code to see if the sum of the unique values of w and y would be equal to the solution, 30. Seeing this in action was really interesting."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 3 - breaking (to illustrate when it breaks)\n\nz = torch.zeros(5,5)\n\ntorch.unique(z)\n\ntest = torch.tensor([[5,4,3],\n                     [6,7,8],\n                     [9,10,11]])\ndel(test)\n\nprint(z)\ntorch.unique(test)","execution_count":15,"outputs":[{"name":"stdout","output_type":"stream","text":"tensor([[0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.]])\n"},{"ename":"NameError","evalue":"name 'test' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-e1851afb9461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"]}]},{"metadata":{},"cell_type":"markdown","source":"The unique function works even with a zero matrix. To break it, the variable the function is called for must not exist/ be undefined. We can see this when I delete the test variable."},{"metadata":{},"cell_type":"markdown","source":"Finding unique values in tensors is important, I imagine for the same reasons it is important for finding them in a dataset: to avoid duplicates. Duplicates can skew the results of a deep learning model and prior analyses."},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\n\nAfter covering both common and linear algebra functions in PyTorch, I can see I still have a lot to learn and discover about how all of these functions collaborate to build neural networks and accomplish machine learning tasks. I definitely plan to revist the PyTorch documentation for more interesting functions to play with. "},{"metadata":{},"cell_type":"markdown","source":"## Reference Links\nProvide links to your references and other interesting articles about tensors\n* Official documentation for `torch.Tensor`: https://pytorch.org/docs/stable/tensors.html\n* ..."},{"metadata":{"trusted":false},"cell_type":"code","source":"!pip install jovian --upgrade --quiet","execution_count":27,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import jovian","execution_count":28,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"jovian.commit()","execution_count":null,"outputs":[{"data":{"application/javascript":"window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})","text/plain":"<IPython.core.display.Javascript object>"},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":"[jovian] Attempting to save notebook..\u001b[0m\n[jovian] Please enter your API key ( from https://jovian.ml/ ):\u001b[0m\nAPI KEY: "}]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}